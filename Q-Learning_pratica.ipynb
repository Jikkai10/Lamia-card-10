{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para maiores testes vamos mudar alguns argumentos no nosso treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\", render_mode='ansi').env #New versions keep getting released; if -v3 doesn't work, try -v2 or -v4\n",
    "streets.reset()\n",
    "\n",
    "initial_state = streets.encode(2, 3, 2, 0)\n",
    "\n",
    "streets.s = initial_state\n",
    "\n",
    "print(\"\\n\" + streets.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente mantemos os mesmos como base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_table1 = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.1 # porcentagem de aprendizado por ciclo\n",
    "discount_factor = 0.6\n",
    "exploration = 0.1 # chance de tomar uma decisão aleatória\n",
    "epochs = 10000 # quantidade de ciclos\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    state = state[0]\n",
    "    while not done:\n",
    "        \n",
    "        random_value = random.uniform(0, 1)\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Toma uma decisão aleatória\n",
    "        else:\n",
    "            action = np.argmax(q_table1[state]) # Pega a posição do maior valor de q\n",
    "        \n",
    "        \n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        \n",
    "        prev_q = q_table1[state, action]\n",
    "        next_max_q = np.max(q_table1[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table1[state, action] = new_q\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse aumentamos a aprendizagem por ciclo, mas diminuimos a quantidade de ciclos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table2 = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.5 # porcentagem de aprendizado por ciclo\n",
    "discount_factor = 0.6\n",
    "exploration = 0.1 # chance de tomar uma decisão aleatória\n",
    "epochs = 5000 # quantidade de ciclos\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    state = state[0]\n",
    "    while not done:\n",
    "        \n",
    "        random_value = random.uniform(0, 1)\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Toma uma decisão aleatória\n",
    "        else:\n",
    "            action = np.argmax(q_table2[state]) # Pega a posição do maior valor de q\n",
    "        \n",
    "        \n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        \n",
    "        prev_q = q_table2[state, action]\n",
    "        next_max_q = np.max(q_table2[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table2[state, action] = new_q\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse aumentamos a quantidade de ciclos e a chance de exploração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table3 = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.1 # porcentagem de aprendizado por ciclo\n",
    "discount_factor = 0.6\n",
    "exploration = 0.5 # chance de tomar uma decisão aleatória\n",
    "epochs = 20000 # quantidade de ciclos\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    state = state[0]\n",
    "    while not done:\n",
    "        \n",
    "        random_value = random.uniform(0, 1)\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Toma uma decisão aleatória\n",
    "        else:\n",
    "            action = np.argmax(q_table3[state]) # Pega a posição do maior valor de q\n",
    "        \n",
    "        \n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        \n",
    "        prev_q = q_table3[state, action]\n",
    "        next_max_q = np.max(q_table3[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table3[state, action] = new_q\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse aumentamos a taxa de aprendizagem e a chance de exploração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table4 = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.5 # porcentagem de aprendizado por ciclo\n",
    "discount_factor = 0.6\n",
    "exploration = 0.5 # chance de tomar uma decisão aleatória\n",
    "epochs = 10000 # quantidade de ciclos\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    state = state[0]\n",
    "    while not done:\n",
    "        \n",
    "        random_value = random.uniform(0, 1)\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Toma uma decisão aleatória\n",
    "        else:\n",
    "            action = np.argmax(q_table4[state]) # Pega a posição do maior valor de q\n",
    "        \n",
    "        \n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        \n",
    "        prev_q = q_table4[state, action]\n",
    "        next_max_q = np.max(q_table4[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        q_table4[state, action] = new_q\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, testamos todos juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number 100 Step 14\n",
      "+---------+\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "trips = [0,0,0,0]\n",
    "for tripnum in range(1, 101):\n",
    "    state = streets.reset()\n",
    "    state = state[0]\n",
    "    state_save = state\n",
    "    done = False\n",
    "    trip_length = 0\n",
    "    \n",
    "    \n",
    "    while not done and trip_length < 25:\n",
    "        action = np.argmax(q_table1[state])\n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render())\n",
    "        \n",
    "        state = next_state\n",
    "        trip_length += 1\n",
    "        \n",
    "    trips[0] += trip_length - 1\n",
    "    trip_length = 0\n",
    "    streets.reset()\n",
    "    streets.s = state_save\n",
    "    state = state_save\n",
    "    done = False\n",
    "    \n",
    "    while not done and trip_length < 25:\n",
    "        action = np.argmax(q_table2[state])\n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render())\n",
    "        \n",
    "        state = next_state\n",
    "        trip_length += 1\n",
    "    trips[1] += trip_length - 1\n",
    "    trip_length = 0\n",
    "    streets.reset()\n",
    "    streets.s = state_save\n",
    "    state = state_save\n",
    "    done = False\n",
    "    \n",
    "    while not done and trip_length < 25:\n",
    "        action = np.argmax(q_table3[state])\n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render())\n",
    "        \n",
    "        state = next_state\n",
    "        trip_length += 1\n",
    "    trips[2] += trip_length - 1\n",
    "    trip_length = 0\n",
    "    streets.reset()\n",
    "    streets.s = state_save\n",
    "    state = state_save\n",
    "    done = False\n",
    "    \n",
    "    while not done and trip_length < 25:\n",
    "        action = np.argmax(q_table4[state])\n",
    "        next_state, reward, done, info, x = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render())\n",
    "        \n",
    "        state = next_state\n",
    "        trip_length += 1\n",
    "    trips[3] += trip_length - 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não há grande diferença nas médias apresentadas, podendo mudar a melhor em diferentes execuções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média 1: 12.66\n",
      "Média 2: 13.15\n",
      "Média 3: 12.72\n",
      "Média 4: 13.43\n"
     ]
    }
   ],
   "source": [
    "print(f'Média 1: {trips[0]/100}')\n",
    "print(f'Média 2: {trips[1]/100}')\n",
    "print(f'Média 3: {trips[2]/100}')\n",
    "print(f'Média 4: {trips[3]/100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
